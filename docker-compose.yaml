version: "3.3"
services:
  imagefrontend: # The App
    image: transparent-ai/imagefrontend
    environment:
      API_HOST: api
      API_PORT: 8050
      PYTHONUNBUFFERED: 1
    ports:
      - "8888:8888"
  api: # Model API which includes pre and post processing
    image: transparent-ai/api
    environment:
      TARGET_ENDPOINT: "http://style:8000"
      TARGET_MODEL: "magenta_image_stylization"
      TARGET_ENDPOINT_CPU_NORMAL: "http://style:8000"
      TARGET_NAME_CPU_NORMAL: "magenta_image_stylization"
      TARGET_ENDPOINT_CPU_OPTIMIZED: "http://style:8000"
      TARGET_MODEL_CPU_OPTIMIZED: "magenta_image_stylization"
      TARGET_ENDPOINT_GPU_NORMAL: "http://style:8000"
      TARGET_MODEL_GPU_NORMAL: "magenta_image_stylization"
      TARGET_ENDPOINT_GPU_OPTIMIZED: "http://style:8000"
      TARGET_MODEL_GPU_OPTIMIZED: "magenta_image_stylization"
    ports:
      - "8050:8050"
  style: # Model runtime containerized by OctoML CLI into a NVIDIA Tritonâ„¢ Inference Server
    image: transparent-ai/style
    ports:
      - "8000:8000"
      - "8001:8001"
      - "8002:8002"
    command: tritonserver --model-repository=octoml/models --strict-model-config=false
