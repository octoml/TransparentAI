version: "3.3"
services:
  frontend: # The App
    image: transparent-ai/frontend
    build: ./frontend
    environment:
      API_HOST: api
      API_PORT: 8050
    ports:
      - "8888:8888"
    depends_on:
      - api
  api: # The pre/post-processing API layer
    image: transparent-ai/api
    build: ./api
    environment:
      TARGET_ENDPOINT_CPU_NORMAL: "http://style:8000"
      TARGET_NAME_CPU_NORMAL: "magenta_image_stylization"
      TARGET_ENDPOINT_CPU_OPTIMIZED: "http://style:8000"
      TARGET_MODEL_CPU_OPTIMIZED: "magenta_image_stylization"
      TARGET_ENDPOINT_GPU_NORMAL: "http://style:8000"
      TARGET_MODEL_GPU_NORMAL: "magenta_image_stylization"
      TARGET_ENDPOINT_GPU_OPTIMIZED: "http://style:8000"
      TARGET_MODEL_GPU_OPTIMIZED: "magenta_image_stylization"
    ports:
      - "8050:8050"
    depends_on:
      - style
  style: # Model runtime containerized by OctoML CLI into a NVIDIA Tritonâ„¢ Inference Server
    image: transparent-ai/style
    ports:
      - "8000:8000"
      - "8001:8001"
      - "8002:8002"
    command: tritonserver --model-repository=octoml/models --strict-model-config=false
